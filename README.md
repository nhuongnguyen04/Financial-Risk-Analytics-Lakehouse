# ğŸ“Š Financial Risk Analytics Lakehouse  
_Architecture & Standards Documentation_  

---

## 1. ğŸ¯ Má»¥c tiÃªu dá»± Ã¡n
- XÃ¢y dá»±ng **Data Lakehouse** cho phÃ¢n tÃ­ch rá»§i ro tÃ i chÃ­nh vÃ  phÃ¡t hiá»‡n gian láº­n.  
- Káº¿t há»£p dá»¯ liá»‡u batch + streaming, phá»¥c vá»¥ cáº£ **BI dashboard** vÃ  **Machine Learning**.  
- Äáº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c quáº£n lÃ½ theo **Bronze â€“ Silver â€“ Gold** layer, cÃ³ tÃ­nh **scalability, reliability vÃ  reproducibility**.  

---

## 2. ğŸ— Kiáº¿n trÃºc tá»•ng quan

### 2.1. ThÃ nh pháº§n chÃ­nh
- **Ingestion**
  - Batch: Airflow jobs (datasets tá»« Kaggle, AlphaVantage, yfinance).  
  - Streaming: Kafka (transactions, logs, auth events).  
- **Storage**
  - Data Lake: MinIO (S3 API), chia bucket theo `bronze/silver/gold`.  
  - Metadata Store: PostgreSQL (catalog, schema, lineage).  
- **Processing**
  - Spark (batch + structured streaming).  
  - PySpark jobs cho ETL vÃ  feature engineering.  
- **Orchestration**
  - Airflow Ä‘á»ƒ quáº£n lÃ½ workflows.  
- **Machine Learning**
  - MLflow cho model training, tracking, registry.  
- **Serving & Monitoring**
  - Streaming scoring (Spark Structured Streaming + Kafka).  
  - Alerts â†’ Kafka/Elasticsearch + Kibana.  
  - BI Dashboard: Apache Superset.  
  - Monitoring: Prometheus + Grafana.  

---

### 2.2. Data Flow

1. **Ingest**
   - Kafka Producers â†’ transaction stream, log stream.  
   - Batch loader â†’ market data, customer info, historical datasets.  
2. **Bronze Layer**
   - LÆ°u raw data nguyÃªn báº£n (schema-on-read, partition theo ngÃ y).  
3. **Silver Layer**
   - Chuáº©n hÃ³a schema, deduplicate, enrich (timezone, geo, join customer info).  
   - Hash/anonymize PII.  
4. **Gold Layer**
   - Fact & Dim tables, feature tables cho ML.  
   - Aggregations cho BI.  
5. **Machine Learning**
   - Offline training (batch).  
   - Online scoring (streaming).  
6. **Serving**
   - Alerts & risk scoring â†’ Kafka topic + Dashboard.  

---

## 3. ğŸ“‚ Data Layers & Schema

### 3.1. Bronze
- **Má»¥c tiÃªu**: Raw data, immutable.  
- **Nguá»“n**: PaySim, Bank Customers, Alpha Vantage, Loghub, synthetic streams.  
- **Quy chuáº©n**:
  - LÆ°u dÆ°á»›i Ä‘á»‹nh dáº¡ng Parquet/JSON.  
  - Partition theo `dt=YYYY-MM-DD`.  
  - KhÃ´ng Ä‘á»•i schema, chá»‰ thÃªm metadata.  

### 3.2. Silver
- **Má»¥c tiÃªu**: Data Ä‘Ã£ lÃ m sáº¡ch, chuáº©n hÃ³a.  
- **Xá»­ lÃ½**:
  - Deduplication.  
  - Standardize timestamp â†’ UTC.  
  - Normalize schema (field naming convention).  
  - Hash/anonymize PII (`customer_id`, `device_id`).  
- **Quy chuáº©n**:
  - Schema cá»‘ Ä‘á»‹nh.  
  - LÆ°u á»Ÿ Parquet + Delta format (support ACID).  

### 3.3. Gold
- **Má»¥c tiÃªu**: Data phá»¥c vá»¥ BI/ML.  
- **Tables**:
  - `fact_transactions`  
  - `dim_customers`  
  - `fact_market_quotes`  
  - `features_transaction_risk`  
- **Quy chuáº©n**:
  - Star schema cho BI.  
  - Feature store document hÃ³a rÃµ rÃ ng.  

---

## 4. ğŸ“ˆ Use Cases

1. **Fraud Detection**  
   - ML model dá»± Ä‘oÃ¡n gian láº­n theo transaction stream.  
2. **Credit Risk Scoring**  
   - Dá»±a trÃªn lá»‹ch sá»­ vay + market indicators.  
3. **Operational Risk Analytics**  
   - PhÃ¢n tÃ­ch logs (auth/system) Ä‘á»ƒ phÃ¡t hiá»‡n báº¥t thÆ°á»ng.  
4. **Business Intelligence**  
   - BÃ¡o cÃ¡o giao dá»‹ch, khÃ¡ch hÃ ng, thá»‹ trÆ°á»ng.  

---

## 5. ğŸ§© Quy chuáº©n Ä‘áº·t tÃªn & quáº£n lÃ½ dá»¯ liá»‡u

### 5.1. Naming conventions
- **Buckets**: `lake/{layer}/{domain}/{table}/{dt}`  
- **Tables**: `layer_domain_table`  
- **Fields**: lowercase, snake_case.  

### 5.2. Data governance
- **Schema Registry** (PostgreSQL + Glue-like table).  
- **Versioning**: Delta Lake.  
- **PII Handling**: Hashing (SHA256), khÃ´ng lÆ°u plaintext.  

---

## 6. ğŸ¤– Machine Learning Workflow

1. **Data Prep**: Silver/Gold tables â†’ feature engineering.  
2. **Model Training**: XGBoost/LightGBM.  
3. **Model Tracking**: MLflow (params, metrics, artifacts).  
4. **Model Registry**: promote tá»« `Staging` â†’ `Production`.  
5. **Serving**:  
   - Batch scoring (Airflow).  
   - Real-time scoring (Spark Structured Streaming + Kafka).  

---

## 7. ğŸ›  Operational Requirements

- **Orchestration**: Airflow DAG cho ingest, transform, training, monitoring.  
- **Monitoring**:  
  - Prometheus (infra, Kafka, Spark metrics).  
  - Grafana dashboards.  
- **Data Quality**: Great Expectations/Deequ validation.  
- **Logging**: Centralized logs (ELK stack).  
- **Resilience**:  
  - Retry cÆ¡ cháº¿ trong Airflow & Spark.  
  - Kafka replication factor â‰¥ 2.  

---

## 8. ğŸ“¦ Deliverables

- Docker Compose environment (Kafka, MinIO, Spark, PostgreSQL, Airflow, MLflow).  
- Data Lakehouse (Bronze/Silver/Gold).  
- Feature store & schema dictionary.  
- ML models (logged in MLflow).  
- Streaming scoring + alerts.  
- BI dashboards (Superset/Kibana).  
- Monitoring setup (Prometheus + Grafana).  
- Documentation:  
  - Architecture design.  
  - Data schemas.  
  - Runbook váº­n hÃ nh.  

---

## 9. âœ… Quy táº¯c kiá»ƒm tra & review

- **Code**: Theo PEP8 (Python), linting vá»›i `black` & `flake8`.  
- **ETL Jobs**: Unit test báº±ng `pytest`.  
- **Data Pipeline**: Validation trÆ°á»›c khi Ä‘áº©y Silver/Gold.  
- **Model**: YÃªu cáº§u log ROC-AUC â‰¥ 0.85 trÆ°á»›c khi promote Production.  
- **Documentation**: Má»i schema & pipeline Ä‘á»u pháº£i cÃ³ markdown/docs kÃ¨m theo.  

---
